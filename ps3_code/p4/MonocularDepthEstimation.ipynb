{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MonocularDepthEstimation",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBciS_TD3JVl"
      },
      "source": [
        "# CS231a PSET 3 Problem 4: Monocular Depth Estimation\n",
        "\n",
        "Building on the idea of learning useful representations for downstream tasks we saw in the last problem, in this problem you will see how this can be done for the task of monocular depth estimation.\n",
        "\n",
        "**Using a GPU**. Make sure to first change your runtime to use a GPU: click Runtime -> Change runtime type -> Hardware Accelerator -> GPU and your Colab instance will automatically be backed by GPU compute.\n",
        "\n",
        "Now, let's download the [NYU Depth dataset](https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html) we'll be working with. First, you should upload the 'problem4' directory as well as the 'checkpoints' and 'examples' directories onto a location of your choosing in Drive and run the following to have access to the code within it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwQRvE4C3gf5"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# enter the foldername in your Drive where you have saved the unzipped\n",
        "# 'problem4' folder containing the '.py' files needed for this problem\n",
        "# e.g. '/content/drive/MyDrive/cs231a/monocular_depth_estimation'\n",
        "FOLDERNAME = None\n",
        "\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "%cd drive/My\\ Drive\n",
        "%cp -r $FOLDERNAME/problem4/download_data.py ../../\n",
        "%cd ../../\n",
        "\n",
        "!python download_data.py\n",
        "\n",
        "%cd drive/My\\ Drive\n",
        "%cd $FOLDERNAME"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55cphY32S2uM"
      },
      "source": [
        "If all is set up correctly, you should now get the 4.4G dataset stored in this Colaborotary runtime. Note that you'll need to redownload this data whenever you reconnect to a fresh runtime!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TM_rDf34_xC5"
      },
      "source": [
        "# Checking out the data\n",
        "\n",
        "Let's start by having a look at what's in the NYU dataset. For that, finish the marked sections in data.py, and then run the following code:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJqDYf2__-HF"
      },
      "source": [
        "from problem4.data import get_data_loaders \n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import gc\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [12, 8]\n",
        "plt.rcParams['figure.dpi'] = 100 \n",
        "\n",
        "tensorToImage = torchvision.transforms.ToPILImage()\n",
        "trainloader, testloader = get_data_loaders(\"/content/data/nyu_depth.zip\", \n",
        "                                           batch_size=4)\n",
        "dataiter = iter(trainloader)\n",
        "fig, axs = plt.subplots(3, 2)\n",
        "for i in range(3):\n",
        "    data = next(dataiter)\n",
        "    axs[i, 0].imshow(tensorToImage(data['image'][0]))\n",
        "    axs[i, 1].imshow(tensorToImage(data['depth'][0]), cmap='gray')\n",
        "    axs[i, 0].axis('off')\n",
        "    axs[i, 1].axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTffBCOz7qwz"
      },
      "source": [
        "# Training the model\n",
        "\n",
        "Next, we can go ahead and train the model once you complete the appropriate parts of losses.py and training.py. Let's just train for one epoch first (this will take around 3 hours!):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2a_1JM754no"
      },
      "source": [
        "Before we run training, let's visualize the training progress using [Tensorboard](https://www.tensorflow.org/tensorboard). When you run the following, you should see the scalars tab showing the loss gradually going down once training starts. If you go to the 'images' tab, you can also be able to observe the 'Ours' images getting better over time, with the 'Diff' images showing less disparity from the ground truth over time:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu8yEUgBPpfM"
      },
      "source": [
        "!pip install tensorboardX\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZqgjjPU9HvL"
      },
      "source": [
        "import problem4.training \n",
        "from importlib import reload  \n",
        "problem4.training = reload(problem4.training)#reload when debugging to have updated code\n",
        "problem4.training.train(1, trainloader, testloader, lr=0.0001, pretrained=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VebaLqiUsR2K"
      },
      "source": [
        "# Testing the trained model\n",
        "\n",
        "Now that the model has trained (for only one epoch!), we can take a look at how good it is at predicting depth given RGB images. Run the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sv15PJoHy4sw"
      },
      "source": [
        "import problem4.testing\n",
        "problem4.testing = reload(problem4.testing)\n",
        "\n",
        "problem4.testing.test('checkpoints/ckpt_0_pretrained.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0Yk5uX2dUrl"
      },
      "source": [
        "# Training without feature transfer\n",
        "\n",
        "Now let's see what happens if we train without transferring over features. We will once again load up Tensorboard and then start training, and can observe the difference in the loss function and image quality between the two ways of training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBLUfSSHUudB"
      },
      "source": [
        "%tensorboard --logdir runs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8WhilMLgK2I"
      },
      "source": [
        "problem4.training = reload(problem4.training)#reload when debugging to have updated code\n",
        "problem4.training.train(1, trainloader, testloader, lr=0.0001, pretrained=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UafdyTJShKH"
      },
      "source": [
        "problem4.testing.test('checkpoints/ckpt_0_not_pretrained.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HImhN6DFTkfi"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "That's it! You have now trained a model for monocular depth estimation, and saw how transfer learning of learned features can result in better convergence compared to learning from scratch. As noted in the PDF, you now just need to download this notebook to submit alongside your python files.\n",
        "\n",
        "Credits: this assignment was adapted from [this](https://github.com/pranjaldatta/DenseDepth-Pytorch) code base.\n"
      ]
    }
  ]
}