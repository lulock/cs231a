{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "RepresentationLearning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "ycNqw0jQJESY"
      },
      "source": [
        "# CS231a PSET 3 Problem 3: Representation Learning with Self-Supervised Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "uDyejdg_JESZ"
      },
      "source": [
        "# Problem Layout\n",
        "\n",
        "In this notebook, we will be using the [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database) to show case how self-supervised representation learning can be utilized for more efficient training in downstream tasks. We will do the following things:\n",
        "\n",
        "1. Train a classifier from scratch on the MNIST dataset and observe how fast and well it learns.\n",
        "\n",
        "2. Train useful representations via predicting digit rotations, rather than classifying digits.\n",
        "\n",
        "3. Transfer our rotation pretraining features to solve the classification task with much less data than in step 1.\n",
        "\n",
        "First, you should upload the 'problem3' directory onto a location of your choosing in Drive and run the following to have access to the code within it:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IcaTRbE5mk6"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# enter the foldername in your Drive where you have saved the unzipped\n",
        "# 'problem 3' folder containing the '.py' files needed for this problem\n",
        "# e.g. '/content/drive/MyDrive/cs231a/representation_learning':\n",
        "FOLDERNAME = None\n",
        "\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "%cd drive/My\\ Drive\n",
        "%cd $FOLDERNAME"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11dNVlk9on-h"
      },
      "source": [
        "import problem3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4lEsdVToylL"
      },
      "source": [
        "If the above import of problem3 works, you are ready to get going with the rest of this problem! Before that, let's make sure you allocate a GPU so that code runs faster: click Runtime -> Change runtime type -> Hardware Accelerator -> GPU and your Colab instance will automatically be backed by GPU compute."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "P-iAbOZEJESg"
      },
      "source": [
        "# PyTorch MNIST Data Preparation\n",
        "\n",
        "First, let's get the data prepared. Luckily, PyTorch has a handy function to download it for us in its [torchvision.datasets](https://pytorch.org/docs/stable/torchvision/datasets.html#cifar) package:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-23T16:49:22.731116Z",
          "start_time": "2020-03-23T16:49:22.710079Z"
        },
        "hidden": true,
        "id": "swy9dHIqJESg"
      },
      "source": [
        "# Download MNIST dataset from PyTorch \n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.1307,), (0.3081,)),\n",
        "                              ])\n",
        "PATH_TO_STORE_DATA = 'data/'\n",
        "torchvision.datasets.MNIST(PATH_TO_STORE_DATA, download=True, train=True, \n",
        "                                             transform=transform)\n",
        "torchvision.datasets.MNIST(PATH_TO_STORE_DATA, download=True, train=False, \n",
        "                                            transform=transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mxmz5akRjg2W"
      },
      "source": [
        "Now that we have downloaded the data, we will implement a PyTorch [Dataset](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html) so that we can load subsets of the full MNIST dataset and use either digit identity or digit rotation as the label for a given image. Fill in the requisite bits of code in data.py (marked with TODO), (you can either do so directly through the file explorer on the left or do so locally and re-upload it), and try to execute the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ3Ojrcvjfj-"
      },
      "source": [
        "from importlib import reload  \n",
        "import problem3.data "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqDY5XfFmHvo"
      },
      "source": [
        "Now, let's create an instance of this Dataset for training MNIST digit classification. We will create two versions of the training dataset, one with all the data and one with a small subset. If you have bugs in your code, simply modify data.py further (you can either do so directly through the file explorer on the left or do so locally and re-upload it)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87wqQ88yxnSm"
      },
      "source": [
        "problem3.data = reload(problem3.data) #reload for making changes during debugging\n",
        "train_full_dataset = problem3.data.MNISTDataset('data/MNIST/processed/training.pt', \n",
        "                                          pct=1.0, classify_digit_type=True)\n",
        "test_full_dataset = problem3.data.MNISTDataset('data/MNIST/processed/test.pt', \n",
        "                                         pct=1.0, classify_digit_type=True)\n",
        "print('Full dataset: {0} Training Samples | {1} Test Samples'.format(\n",
        "    len(train_full_dataset), len(test_full_dataset)))\n",
        "train_small_dataset = problem3.data.MNISTDataset('data/MNIST/processed/training.pt', \n",
        "                                          pct=0.01, classify_digit_type=True)\n",
        "print('Small train dataset: {0} Training Samples'.format(len(train_small_dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EC323C3768BK"
      },
      "source": [
        "Let's use the handy show_batch function to get an idea of what's in the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn9mJMLR7AUU"
      },
      "source": [
        "train_full_dataset.show_batch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "gAOwwDckJESZ"
      },
      "source": [
        "# PyTorch Vision Model\n",
        "\n",
        "Next, we need to define our neural net architectures for training on the data. Because we want to ultimately train for two objects (digit classification and rotation classification), we will do this via several classes so that the weights gotten from representation learning can be re-used later for more efficient digit classification.\n",
        "Fill in the marked portions of models.py, and try to execute the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-23T16:49:22.659560Z",
          "start_time": "2020-03-23T16:49:22.655226Z"
        },
        "hidden": true,
        "id": "ucYL8j4fJESb"
      },
      "source": [
        "import problem3.models\n",
        "problem3.models = reload(problem3.models) #reload for making changes during debugging\n",
        "\n",
        "image_embed_net = problem3.models.ImageEmbedNet().cuda()\n",
        "classify_net = problem3.models.ClassifyNet(10).cuda()\n",
        "mnist_classify_model = problem3.models.ImageClassifyModel(image_embed_net, \n",
        "                                                          classify_net)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afWQLrriqcu7"
      },
      "source": [
        "If running the above results in errors, revise your code in models.py the file as in the last section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSy0y-7zk5Jz"
      },
      "source": [
        "# Training for MNIST Digit Prediction\n",
        "\n",
        "Let's now implement a method for training on the dataset with the models we defined above. We will create a re-usable function that can be used for both representation learning and learning to classify MNIST digits. This will involve the following:\n",
        "*   Given the dataset, creating a PyTorch [DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) which can take care of shuffling the dataset as well as combining multiple image.\n",
        "*   Creating a PyTorch loss function that can be used for optimizing our model for the task of classification. We will use the standard [Cross Entropy Loss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html).\n",
        "*   Creating a PyTorch [optimizer](https://pytorch.org/docs/stable/optim.html) to update the weights of the model given the loss computation.\n",
        "*   Lastly, our two training loops (one for the number of epochs, and one for iterating over the dataset) in which we use all the above to train the model.\n",
        "\n",
        "Fill in the relevant portions of code in training.py, and try to execute the following to go ahead and train on the MNIST digit classification task. If training.py is finished, we now just need to call its train function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CDqWDBGzn1L"
      },
      "source": [
        "import problem3.training\n",
        "\n",
        "problem3.training = reload(problem3.training)\n",
        "# Create fresh models before every run to make sure we start from scratch\n",
        "image_embed_net = problem3.models.ImageEmbedNet().cuda()\n",
        "classify_net = problem3.models.ClassifyNet(10).cuda()\n",
        "mnist_classify_model = problem3.models.ImageClassifyModel(image_embed_net, \n",
        "                                                          classify_net)\n",
        "\n",
        "problem3.training.train(train_full_dataset, mnist_classify_model, 16, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTETMWRO5xIg"
      },
      "source": [
        "You should get training accuracy of at least 0.98. With the model now trained, let's implement a test function and call it to see how well it works on the test set. Finish the marked portions in testing.py and run the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOW9HX8N5SSt"
      },
      "source": [
        "import problem3.testing\n",
        "\n",
        "problem3.testing = reload(problem3.testing)\n",
        "problem3.testing.test(test_full_dataset, mnist_classify_model, 16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfGZfDvX6Xwh"
      },
      "source": [
        "You should get test set accuracy similar to the train set accuracy.\n",
        "Now, let's try training on the smaller train set, and see how well the model can work on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoL5ycTp7NMb"
      },
      "source": [
        "image_embed_net = problem3.models.ImageEmbedNet().cuda()\n",
        "classify_net = problem3.models.ClassifyNet(10).cuda()\n",
        "mnist_classify_model = problem3.models.ImageClassifyModel(image_embed_net, classify_net)\n",
        "problem3.training.train(train_small_dataset, mnist_classify_model, 16, 10)\n",
        "problem3.testing.test(test_full_dataset, mnist_classify_model, 16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLCi6S2qvFyi"
      },
      "source": [
        "You should get both low training and testing accuracy, since we are not training with much less data. If we iterate over the data for more epochs it is possible to get better results, but still far below the accuracy gotten with the full dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7L7sy9-vts4"
      },
      "source": [
        "image_embed_net = problem3.models.ImageEmbedNet().cuda()\n",
        "classify_net = problem3.models.ClassifyNet(10).cuda()\n",
        "mnist_classify_model = problem3.models.ImageClassifyModel(image_embed_net, classify_net)\n",
        "problem3.training.train(train_small_dataset, mnist_classify_model, 16, 100)\n",
        "problem3.testing.test(test_full_dataset, mnist_classify_model, 16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "YItknfArJESi"
      },
      "source": [
        "# Representation Learning via Rotation Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-23T16:28:42.437483Z",
          "start_time": "2020-03-23T16:28:42.431824Z"
        },
        "hidden": true,
        "id": "uDYBx88AJESh"
      },
      "source": [
        "Now, let's define new datasets for doing our representation learning by predicting the rotation of MNIST digits, and once again call show_batch to get a look at the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-23T16:49:23.193640Z",
          "start_time": "2020-03-23T16:49:22.790204Z"
        },
        "hidden": true,
        "id": "9qzZrVKtJESi"
      },
      "source": [
        "problem3.data = reload(problem3.data) #reload for making changes during debugging\n",
        "\n",
        "train_rotation_dataset = problem3.data.MNISTDataset('data/MNIST/processed/training.pt', \n",
        "                                          pct=1.0, classify_digit_type=False)\n",
        "test_rotation_dataset = problem3.data.MNISTDataset('data/MNIST/processed/test.pt', \n",
        "                                         pct=1.0, classify_digit_type=False)\n",
        "train_rotation_dataset.show_batch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "Ca8WNHxRJESj"
      },
      "source": [
        "Now, let's train a model on the rotation prediction task by once again using our train function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-23T16:50:25.874982Z",
          "start_time": "2020-03-23T16:50:25.871423Z"
        },
        "hidden": true,
        "id": "Qv5IDvkrJESj"
      },
      "source": [
        "rotation_image_embed_net = problem3.models.ImageEmbedNet().cuda()\n",
        "rotation_classify_net = problem3.models.ClassifyNet(8).cuda()\n",
        "mnist_rotation_classify_model = problem3.models.ImageClassifyModel(rotation_image_embed_net, \n",
        "                                                   rotation_classify_net)\n",
        "problem3.training.train(train_rotation_dataset, mnist_rotation_classify_model, 16, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lkw_gKCjwpMc"
      },
      "source": [
        "We should once again get testing accuracy similar to training accuracy: (at least 0.95):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVSzgPLf-LI_"
      },
      "source": [
        "problem3.testing.test(test_rotation_dataset, mnist_rotation_classify_model, 16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "vMiIE-BfJESk"
      },
      "source": [
        "# Fine-Tuning for MNIST digit classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "lqZ3R7SiJESk"
      },
      "source": [
        "Now that we have pretrained our model on the rotation prediction task, let's reuse the image embed part of it to train it for the task of digit classification. We will use load_state_dict to transfer over the weights from the trained model to a new instance of it, so we can later re-use the same representation learning weights in a different setup. Let's first try it on the full dataset and see how fast it converges compared to when we did not pretrain it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-23T16:50:25.924413Z",
          "start_time": "2020-03-23T16:50:25.893074Z"
        },
        "hidden": true,
        "id": "Z96Vg9ruJESk"
      },
      "source": [
        "image_embed_net = problem3.models.ImageEmbedNet().cuda()\n",
        "image_embed_net.load_state_dict(rotation_image_embed_net.state_dict())\n",
        "classify_net = problem3.models.ClassifyNet(10).cuda()\n",
        "mnist_classify_model = problem3.models.ImageClassifyModel(image_embed_net, classify_net)\n",
        "problem3.training.train(train_full_dataset, mnist_classify_model, 16, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMYyWBz--Itv"
      },
      "source": [
        "problem3.testing.test(test_full_dataset, mnist_classify_model, 16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0o03jVgO-crj"
      },
      "source": [
        "Now, let's try training with the small dataset again and see how well that works:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDanA7ls-cB_"
      },
      "source": [
        "image_embed_net = problem3.models.ImageEmbedNet().cuda()\n",
        "image_embed_net.load_state_dict(rotation_image_embed_net.state_dict())\n",
        "classify_net = problem3.models.ClassifyNet(10).cuda()\n",
        "mnist_classify_model = problem3.models.ImageClassifyModel(image_embed_net, classify_net)\n",
        "problem3.training.train(train_small_dataset, mnist_classify_model, 16, 10)\n",
        "problem3.testing.test(test_full_dataset, mnist_classify_model, 16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFp_O553ypvD"
      },
      "source": [
        "Like before, we can train on the data for long to get better results, but as you can see above training with just 10 epochs works much better than before with the pretrained features. Still, let's see the results with 50 epochs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoXnGifRypG1"
      },
      "source": [
        "image_embed_net = problem3.models.ImageEmbedNet().cuda()\n",
        "image_embed_net.load_state_dict(rotation_image_embed_net.state_dict())\n",
        "classify_net = problem3.models.ClassifyNet(10).cuda()\n",
        "mnist_classify_model = problem3.models.ImageClassifyModel(image_embed_net, classify_net)\n",
        "problem3.training.train(train_small_dataset, mnist_classify_model, 16, 50)\n",
        "problem3.testing.test(test_full_dataset, mnist_classify_model, 16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNMUbGqh_AJr"
      },
      "source": [
        "Not bad! We can also try training without optimizing for the image embedding layers, and just train the classifier part of the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O-vRbbA-_ka"
      },
      "source": [
        "image_embed_net = problem3.models.ImageEmbedNet().cuda()\n",
        "image_embed_net.load_state_dict(rotation_image_embed_net.state_dict())\n",
        "classify_net = problem3.models.ClassifyNet(10).cuda()\n",
        "mnist_classify_model = problem3.models.ImageClassifyModel(image_embed_net, classify_net,\n",
        "                                          exclude_embed_params=True)\n",
        "problem3.training.train(train_small_dataset, mnist_classify_model, 16, 50)\n",
        "problem3.testing.test(test_full_dataset, mnist_classify_model, 16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "oK7GsCQsJESm"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "That's it! As noted in the PDF, you now just need to download this notebook to submit alongside your python files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRqgNjfJSZiT"
      },
      "source": [
        "Credits: Aspects of this notebook have been adapted from [here](https://colab.research.google.com/github/AmarSaini/Epoching-Blog/blob/master/_notebooks/2020-03-23-Self-Supervision-with-FastAI.ipynb#scrollTo=lsQmOOQsMVFT)"
      ]
    }
  ]
}